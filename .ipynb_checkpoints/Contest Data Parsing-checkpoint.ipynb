{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a7cc9312",
   "metadata": {},
   "outputs": [],
   "source": [
    "####\n",
    "## THIS NOTEBOOOK GOES THROUGH EACH OF THE GIVEN CONTEST FILES AND \n",
    "## PARSES CAPTAIN/FLEX OWNERSHIP AS WELL AS TOTAL DUPLICATIONS FOR EACH SUBMITTED LINEUP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "09e9a2d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input 1 to parse training data, 2 for test data: 2\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from os.path import isfile, join\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "\n",
    "train_or_test = input('Input 1 to parse training data, 2 for test data: ')\n",
    "\n",
    "## IM USING DraftKings_Contest_Files_1 FOR TRAINING DATA AND DraftKings_Contest_Files_2 FOR TEST DATA\n",
    "path = ''\n",
    "if train_or_test == '1': path = os.getcwd() + '/DraftKings_Contest_Files_1'\n",
    "elif train_or_test == '2': path = os.getcwd() + '/DraftKings_Contest_Files_2'\n",
    "else: raise Exception(\"Invalid Input\")\n",
    "\n",
    "contest_files = [f for f in os.listdir(path) if f[-4:] == '.csv']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "84b5bc49",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "## THESE FILES HELP US MATCHUP PLAYER IDS AND NAMES\n",
    "nfl_players = pd.read_csv('NFL_PLAYERS.csv')\n",
    "nfl_teams = pd.read_csv('NFL_TEAMS.csv')\n",
    "\n",
    "nfl_players = nfl_players[['id', 'draftkings_name']]\n",
    "nfl_players = nfl_players.dropna()\n",
    "nfl_players = nfl_players.rename(columns={'draftkings_name': 'name'})\n",
    "nfl_players = nfl_players.replace({'Van Jefferson': 'Van Jefferson Jr.', 'John Kelly Jr.': 'John Kelly'})\n",
    "\n",
    "nfl_teams = nfl_teams[['id', 'name']]\n",
    "nfl_teams = nfl_teams.dropna()\n",
    "nfl_teams = nfl_teams.replace({'Commanders': 'WAS Football Team'})\n",
    "\n",
    "dk_name_ids_cpt = pd.concat([nfl_players, nfl_teams]).reset_index(drop=True)\n",
    "dk_name_ids_cpt = dk_name_ids_cpt.rename(columns={'id': 'cpt_id', 'name': 'CPT'})\n",
    "dk_name_ids_flex = pd.concat([nfl_players, nfl_teams]).reset_index(drop=True)\n",
    "dk_name_ids_flex = dk_name_ids_flex.rename(columns={'id': 'flex_id', 'name': 'FLEX'})\n",
    "\n",
    "showdown_links = pd.read_csv('Showdown_Links.csv')\n",
    "showdown_projections = pd.read_csv('NFL_SHOWDOWN_PROJECTIONS.csv')\n",
    "showdown_projections['full_name'] = showdown_projections.apply(lambda r: r['first_name'] + ' ' + r['last_name'] if r['position'] != 'DST' else r['last_name'], axis=1)\n",
    "cpt_showdown_projections_merge_df = showdown_projections[['slate_id', 'player_id', 'position', 'salary', 'projection', 'team_id', 'team_name', 'opponent_id', 'opponent_name', 'home']]\n",
    "cpt_showdown_projections_merge_df = cpt_showdown_projections_merge_df.rename(columns={\n",
    "    'slate_id': 'SLATE ID',\n",
    "    'player_id': 'CPT_PLAYER_ID',\n",
    "    'position': 'CPT_POSITION',\n",
    "    'salary': 'CPT_SALARY',\n",
    "    'projection': 'CPT_BASE_PROJECTION',\n",
    "    'team_id': 'CPT_TEAM_ID',\n",
    "    'team_name': 'CPT_TEAM_NAME',\n",
    "    'opponent_id': 'CPT_OPP_ID',\n",
    "    'opponent_name': 'CPT_OPP_NAME',\n",
    "    'home': 'CPT_HOME_AWAY'\n",
    "})\n",
    "\n",
    "flex_showdown_projections_merge_df = showdown_projections[['slate_id', 'player_id', 'position', 'salary', 'projection', 'team_id', 'team_name', 'opponent_id', 'opponent_name', 'home']]\n",
    "flex_showdown_projections_merge_df = flex_showdown_projections_merge_df.rename(columns={\n",
    "    'slate_id': 'SLATE ID',\n",
    "    'player_id': 'FLEX_PLAYER_ID',\n",
    "    'position': 'FLEX_POSITION',\n",
    "    'salary': 'FLEX_SALARY',\n",
    "    'projection': 'FLEX_BASE_PROJECTION',\n",
    "    'team_id': 'FLEX_TEAM_ID',\n",
    "    'team_name': 'FLEX_TEAM_NAME',\n",
    "    'opponent_id': 'FLEX_OPP_ID',\n",
    "    'opponent_name': 'FLEX_OPP_NAME',\n",
    "    'home': 'FLEX_HOME_AWAY'\n",
    "})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f0ff7fe2",
   "metadata": {},
   "outputs": [],
   "source": [
    "### GATHER GAME AND SLATE IDS FOR EACH CONTEST STANDINGS FILE\n",
    "game_ids = {}\n",
    "slate_ids = {}\n",
    "for i in range(len(showdown_links.index)):\n",
    "    l = showdown_links.loc[i, :].tolist()\n",
    "    fid = str(l[4])\n",
    "    gid = l[6]\n",
    "    sid = l[7]\n",
    "    \n",
    "    if fid in game_ids: pass\n",
    "    else: game_ids[fid] = gid\n",
    "        \n",
    "    if fid in slate_ids: pass\n",
    "    else: slate_ids[fid] = sid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "56ce6633",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/aidanhall/opt/miniconda3/lib/python3.9/site-packages/IPython/core/interactiveshell.py:3444: DtypeWarning: Columns (7,8,9) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  exec(code_obj, self.user_global_ns, self.user_ns)\n"
     ]
    }
   ],
   "source": [
    "df_list = []\n",
    "cpt_to_flex_df_list = []\n",
    "\n",
    "for i in range(len(contest_files)):\n",
    "    ## READ IN EACH CONTEST FILE CSV\n",
    "    cs = pd.read_csv(path + '/' + contest_files[i])\n",
    "    \n",
    "    id_string = contest_files[i].replace('.', '-')\n",
    "    id_string_split = id_string.split('-')\n",
    "    contest_id = id_string_split[2]\n",
    "\n",
    "    ## KEEPS TRACK OF TOTAL EXPOSURE FOR EACH PLAYER LISTED AS A CAPTAIN\n",
    "    cpt_exp = {}\n",
    "    \n",
    "    ## KEEPS TRACK OF THE COUNTS OF EACH PLAYER PLAYED AS A FLEX GIVEN A SPECIFIC PLAYER AS CAPTAIN\n",
    "    cpt_to_flex_dict = {}\n",
    "    \n",
    "    ## KEEPS TRACK OF TOTAL EXPOSURE FOR EACH PLAYER LISTED AS A CAPTAIN\n",
    "    flex_exp = {}\n",
    "    \n",
    "    ## THIS DICTIONARY TRACKS THE COUNT OF EACH SUBMITTED LINEUP TO FIND ACTUAL LINEUP DUPLICATE NUMBERS IN THAT CONTEST\n",
    "    lineup_counts = {}\n",
    "    \n",
    "    ## KEEPS TRACK OF THE NUMBER OF ALL NON BLANK SUBMITTED LINEUPS IN EACH CONTEST\n",
    "    lineups_processed = 0\n",
    "\n",
    "    ## GOES THROUGH EACH LINE IN THE FILE\n",
    "    for i in range(len(cs.index)):\n",
    "        lu = cs.loc[i, ['Lineup']].tolist()\n",
    "        ## GETS RID OF ALL BLANK OR RESERVED ENTRIES\n",
    "        if lu == [np.nan]: continue\n",
    "        else: pass\n",
    "        lu_string = lu[0]\n",
    "\n",
    "        \n",
    "        if lu_string in lineup_counts: lineup_counts[lu_string] += 1\n",
    "        else: lineup_counts[lu_string] = 1\n",
    "\n",
    "        ## THE FOLLOWING PARSES EACH LINEUP CELL IN THE CSV TO FIND THE CAPTAIN AND FLEX PLAYER\n",
    "        ## ANNOYINGLY, SOMETIMES THE CAPTAIN IS LISTED AS THE LAST PLAYER AND SOMETIMES LISTED AS THE FIRST PLAYER\n",
    "        lu_string = lu_string.replace('CPT', '|CPT|')\n",
    "        lu_string = lu_string.replace('FLEX', '|FLEX|')\n",
    "        lu_list = lu_string.split('|')\n",
    "\n",
    "        cpt_index = lu_list.index('CPT')\n",
    "        cpt = lu_list[cpt_index + 1]\n",
    "        cpt = cpt.rstrip()\n",
    "        cpt = cpt.lstrip()\n",
    "\n",
    "        if cpt in cpt_exp: cpt_exp[cpt] += 1\n",
    "        else: cpt_exp[cpt] = 1\n",
    "\n",
    "        if cpt in cpt_to_flex_dict: pass\n",
    "        else: cpt_to_flex_dict[cpt] = {}\n",
    "\n",
    "        try:\n",
    "            while True:\n",
    "                lu_list.remove('FLEX')\n",
    "        except ValueError:\n",
    "            pass\n",
    "\n",
    "        try:\n",
    "            while True:\n",
    "                lu_list.remove('CPT')\n",
    "        except ValueError:\n",
    "            pass\n",
    "\n",
    "        try:\n",
    "            while True:\n",
    "                lu_list.remove('')\n",
    "        except ValueError:\n",
    "            pass\n",
    "\n",
    "        for j in range(len(lu_list)):\n",
    "            p = lu_list[j]\n",
    "            if p == '': continue\n",
    "            else: pass\n",
    "\n",
    "            p = p.rstrip()\n",
    "            p = p.lstrip()\n",
    "\n",
    "            if p == cpt: continue\n",
    "            else:\n",
    "                if p in flex_exp: flex_exp[p] += 1\n",
    "                else: flex_exp[p] = 1\n",
    "                if p in cpt_to_flex_dict[cpt]: cpt_to_flex_dict[cpt][p] += 1\n",
    "                else: cpt_to_flex_dict[cpt][p] = 1\n",
    "\n",
    "\n",
    "        lineups_processed += 1\n",
    "\n",
    "    ## UPDATE OUR DICTIONARIES TO SHOW PERCENTAGES RATHER THAN RAW COUNTS\n",
    "    for k in cpt_exp:\n",
    "        cpt_occurances = cpt_exp[k]\n",
    "        cpt_exp[k] = cpt_exp[k] / lineups_processed\n",
    "\n",
    "        for r in cpt_to_flex_dict[k]:\n",
    "            cpt_to_flex_dict[k][r] = cpt_to_flex_dict[k][r] / cpt_occurances\n",
    "\n",
    "    for k in flex_exp:\n",
    "        flex_exp[k] = flex_exp[k] / lineups_processed\n",
    "        \n",
    "    ## THE FOLLOWING SIMPLY FINDS \"EXPECTED\" DUPLICATE NUMBERS FOR EACH LINEUP\n",
    "    ## DEFINED SIMPLY AS THE PRODUCT OF EACH PROJECTED OWNERSHIP FIGURE MULTIPLIED BY TOTAL LINEUPS PLAYED IN THAT CONTEST\n",
    "\n",
    "    lineup_dupes = {}\n",
    "\n",
    "    for i in range(len(cs.index)):\n",
    "        lu = cs.loc[i, ['Lineup']].tolist()\n",
    "        if lu == [np.nan]: continue\n",
    "        else: pass\n",
    "        lu_string = lu[0]\n",
    "\n",
    "        lu_string = lu_string.replace('CPT', '|CPT|')\n",
    "        lu_string = lu_string.replace('FLEX', '|FLEX|')\n",
    "        lu_list = lu_string.split('|')\n",
    "\n",
    "        cpt_index = lu_list.index('CPT')\n",
    "        cpt = lu_list[cpt_index + 1]\n",
    "        cpt = cpt.rstrip()\n",
    "        cpt = cpt.lstrip()\n",
    "\n",
    "        try:\n",
    "            while True:\n",
    "                lu_list.remove('FLEX')\n",
    "        except ValueError:\n",
    "            pass\n",
    "\n",
    "        try:\n",
    "            while True:\n",
    "                lu_list.remove('CPT')\n",
    "        except ValueError:\n",
    "            pass\n",
    "\n",
    "        try:\n",
    "            while True:\n",
    "                lu_list.remove('')\n",
    "        except ValueError:\n",
    "            pass\n",
    "\n",
    "        ownership_rates = []\n",
    "\n",
    "        for j in range(len(lu_list)):\n",
    "            p = lu_list[j]\n",
    "            if p == '': continue\n",
    "            else: pass\n",
    "\n",
    "            p = p.rstrip()\n",
    "            p = p.lstrip()\n",
    "\n",
    "            if p == cpt: ownership_rates.append(cpt_exp[p])\n",
    "            else: ownership_rates.append(flex_exp[p])\n",
    "\n",
    "        expected_dupes = np.prod(ownership_rates) * lineups_processed\n",
    "\n",
    "        if lu[0] in lineup_dupes: pass\n",
    "        else: lineup_dupes[lu[0]] = expected_dupes\n",
    "     \n",
    "    ## GENERATE A DATAFRAME LISTING EACH LINEUP PLAYED IN A SLATE ALONG WITH ITS DUPLICATE NUMBERS AND EXPECTED DUPLICATES\n",
    "    df = pd.DataFrame.from_dict(lineup_counts, orient='index')\n",
    "    df = df.reset_index()\n",
    "    df.columns = ['LINEUP', 'COUNT']\n",
    "    df['EXPECTED DUPES'] = df.apply(lambda r: round(lineup_dupes[r['LINEUP']], 0), axis=1)\n",
    "    df['SLATE ID'] = slate_ids[contest_id]\n",
    "    \n",
    "    df_list.append(df)\n",
    "    \n",
    "    df = pd.DataFrame.from_dict({(i,j): cpt_to_flex_dict[i][j] \n",
    "                           for i in cpt_to_flex_dict.keys() \n",
    "                           for j in cpt_to_flex_dict[i].keys()},\n",
    "                       orient='index')\n",
    "\n",
    "    ## GENERATES A DATAFRAME SHOWING EVERY PLAYER IN EACH SLATE PLAYED IN THE CAPTAIN SPOT\n",
    "    ## ALONG WITH HOW OFTEN EACH PLAYER WAS PLAYED IN A FLEX POSITION ALONG WITH THAT CAPTAIN\n",
    "    df = df.reset_index()\n",
    "    df.columns = ['PAIR', 'PERC']\n",
    "    df['CPT'] = df.apply(lambda r: r['PAIR'][0], axis=1)\n",
    "    df['FLEX'] = df.apply(lambda r: r['PAIR'][1], axis=1)\n",
    "    df['OVR FLEX'] = df.apply(lambda r: flex_exp[r['FLEX']], axis=1)\n",
    "    df['FLEX EXP DIFF'] = df.apply(lambda r: r['PERC'] - r['OVR FLEX'], axis=1)\n",
    "    df['OVR CPT'] = df.apply(lambda r: cpt_exp[r['CPT']], axis=1)\n",
    "    df['CPT FREQ'] = df.apply(lambda r: cpt_exp[r['CPT']] * lineups_processed, axis=1)\n",
    "    df['GAME ID'] = game_ids[contest_id]\n",
    "    df['SLATE ID'] = slate_ids[contest_id]\n",
    "    df = df[['CPT', 'FLEX', 'PERC', 'OVR FLEX', 'FLEX EXP DIFF', 'CPT FREQ', 'OVR CPT', 'GAME ID', 'SLATE ID']].reset_index(drop=True)\n",
    "    \n",
    "    df = df.merge(dk_name_ids_cpt, left_on='CPT', right_on='CPT', how='left')\n",
    "    df = df.merge(dk_name_ids_flex, left_on='FLEX', right_on='FLEX', how='left')\n",
    "    \n",
    "    df = df.merge(cpt_showdown_projections_merge_df, left_on=['SLATE ID', 'cpt_id'], right_on=['SLATE ID', 'CPT_PLAYER_ID'])\n",
    "    df = df.merge(flex_showdown_projections_merge_df, left_on=['SLATE ID', 'flex_id'], right_on=['SLATE ID', 'FLEX_PLAYER_ID'])\n",
    "    \n",
    "    cpt_to_flex_df_list.append(df)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fac704d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_contests = pd.concat(df_list)\n",
    "\n",
    "if train_or_test == '1': all_contests.to_csv('slate_lineups_and_expected_dupes_TRAINING_DATA.csv', index=False)\n",
    "else: all_contests.to_csv('slate_lineups_and_expected_dupes_TEST_DATA.csv', index=False)\n",
    "\n",
    "    \n",
    "cpt_to_flex_rel_df = pd.concat(cpt_to_flex_df_list)\n",
    "\n",
    "if train_or_test == '1': cpt_to_flex_rel_df.to_csv('cpt_flex_relationship_regression_TRAINING_DATA.csv', index=False)\n",
    "else: cpt_to_flex_rel_df.to_csv('cpt_flex_relationship_regression_TEST_DATA.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bb291a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "###\n",
    "## CORRELATION BETWEEN SIMPLE DUPLICATE PREDICTION METHOD AND ACTUAL OBSERVED LINEUP DUPES: .42-.45"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "348e29ba",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
